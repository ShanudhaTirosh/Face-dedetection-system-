<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection System - Fixed Version</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        /* Previous CSS styles remain the same */
        .glass-effect {
            background: rgba(255, 255, 255, 0.2);
            backdrop-filter: blur(8px);
            border-radius: 10px;
            border: 1px solid rgba(255, 255, 255, 0.18);
            padding: 20px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
        }

        body {
            min-height: 100vh;
            background: linear-gradient(45deg, #6a11cb, #2575fc);
            padding: 20px;
        }

        #video-container {
            position: relative;
            margin: auto;
            width: fit-content;
        }

        #face-canvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        .status-message {
            color: white;
            background: rgba(0, 0, 0, 0.7);
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div id="status" class="status-message text-center"></div>
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="glass-effect">
                    <div id="video-container">
                        <video id="video" width="640" height="480" autoplay muted></video>
                        <canvas id="face-canvas" width="640" height="480"></canvas>
                    </div>
                    <div class="mt-3">
                        <button class="btn btn-primary me-2" id="startBtn" disabled>Start Detection</button>
                        <button class="btn btn-danger me-2" id="stopBtn" disabled>Stop Detection</button>
                        <button class="btn btn-success" id="captureBtn" disabled>Capture Face</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Scripts -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('face-canvas');
        const ctx = canvas.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const captureBtn = document.getElementById('captureBtn');
        const statusDiv = document.getElementById('status');
        
        let isDetecting = false;
        let modelLoaded = false;

        function updateStatus(message, isError = false) {
            statusDiv.textContent = message;
            statusDiv.style.backgroundColor = isError ? 'rgba(255,0,0,0.7)' : 'rgba(0,0,0,0.7)';
        }

        // Modified model loading with specific model URLs and better error handling
        async function loadModels() {
            updateStatus('Loading face detection models...');
            
            const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
            
            try {
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
                    faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
                    faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL)
                ]);
                
                modelLoaded = true;
                updateStatus('Models loaded successfully! You can start detection.');
                startBtn.disabled = false;
                captureBtn.disabled = false;
                
            } catch (error) {
                console.error('Error loading models:', error);
                updateStatus('Error loading models. Please check your internet connection and refresh.', true);
            }
        }

        async function startVideo() {
            updateStatus('Accessing camera...');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        width: 640,
                        height: 480,
                        facingMode: 'user'
                    } 
                });
                video.srcObject = stream;
                updateStatus('Camera accessed successfully!');
            } catch (error) {
                console.error('Error:', error);
                updateStatus('Cannot access camera. Please check permissions.', true);
            }
        }

        async function detectFaces() {
            if (!isDetecting || !modelLoaded) return;

            try {
                const detections = await faceapi.detectAllFaces(
                    video,
                    new faceapi.TinyFaceDetectorOptions({
                        inputSize: 512,
                        scoreThreshold: 0.5
                    })
                ).withFaceLandmarks();

                ctx.clearRect(0, 0, canvas.width, canvas.height);

                if (detections.length > 0) {
                    detections.forEach(detection => {
                        // Draw face box
                        ctx.strokeStyle = '#00ff00';
                        ctx.lineWidth = 2;
                        ctx.strokeRect(
                            detection.detection.box.x,
                            detection.detection.box.y,
                            detection.detection.box.width,
                            detection.detection.box.height
                        );

                        // Draw landmarks
                        if (detection.landmarks) {
                            ctx.fillStyle = '#00ff00';
                            detection.landmarks.positions.forEach(point => {
                                ctx.beginPath();
                                ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
                                ctx.fill();
                            });
                        }
                    });
                }
            } catch (error) {
                console.error('Detection error:', error);
                updateStatus('Face detection error. Retrying...', true);
            }

            requestAnimationLet me help you fix the face detection models loading issue. The problem might be related to how we're loading the models. Let's modify the code to make it more reliable and add better error handling.

Here's the corrected version focusing on the model loading and face detection parts:

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection System - Fixed Version</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        /* Previous CSS styles remain the same */
        .glass-effect {
            background: rgba(255, 255, 255, 0.2);
            backdrop-filter: blur(8px);
            border-radius: 10px;
            border: 1px solid rgba(255, 255, 255, 0.18);
            padding: 20px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
        }

        body {
            min-height: 100vh;
            background: linear-gradient(45deg, #6a11cb, #2575fc);
            padding: 20px;
        }

        #video-container {
            position: relative;
            margin: auto;
            width: fit-content;
        }

        #face-canvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        .status-message {
            color: white;
            background: rgba(0, 0, 0, 0.7);
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div id="status" class="status-message text-center"></div>
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="glass-effect">
                    <div id="video-container">
                        <video id="video" width="640" height="480" autoplay muted></video>
                        <canvas id="face-canvas" width="640" height="480"></canvas>
                    </div>
                    <div class="mt-3">
                        <button class="btn btn-primary me-2" id="startBtn" disabled>Start Detection</button>
                        <button class="btn btn-danger me-2" id="stopBtn" disabled>Stop Detection</button>
                        <button class="btn btn-success" id="captureBtn" disabled>Capture Face</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Scripts -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('face-canvas');
        const ctx = canvas.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const captureBtn = document.getElementById('captureBtn');
        const statusDiv = document.getElementById('status');
        
        let isDetecting = false;
        let modelLoaded = false;

        function updateStatus(message, isError = false) {
            statusDiv.textContent = message;
            statusDiv.style.backgroundColor = isError ? 'rgba(255,0,0,0.7)' : 'rgba(0,0,0,0.7)';
        }

        // Modified model loading with specific model URLs and better error handling
        async function loadModels() {
            updateStatus('Loading face detection models...');
            
            const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
            
            try {
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
                    faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
                    faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL)
                ]);
                
                modelLoaded = true;
                updateStatus('Models loaded successfully! You can start detection.');
                startBtn.disabled = false;
                captureBtn.disabled = false;
                
            } catch (error) {
                console.error('Error loading models:', error);
                updateStatus('Error loading models. Please check your internet connection and refresh.', true);
            }
        }

        async function startVideo() {
            updateStatus('Accessing camera...');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        width: 640,
                        height: 480,
                        facingMode: 'user'
                    } 
                });
                video.srcObject = stream;
                updateStatus('Camera accessed successfully!');
            } catch (error) {
                console.error('Error:', error);
                updateStatus('Cannot access camera. Please check permissions.', true);
            }
        }

        async function detectFaces() {
            if (!isDetecting || !modelLoaded) return;

            try {
                const detections = await faceapi.detectAllFaces(
                    video,
                  new faceapi.TinyFaceDetectorOptions({
                        inputSize: 512,
                        scoreThreshold: 0.5
                    })
                ).withFaceLandmarks();

                ctx.clearRect(0, 0, canvas.width, canvas.height);

                if (detections.length > 0) {
                    detections.forEach(detection => {
                        // Draw face box
                        ctx.strokeStyle = '#00ff00';
                        ctx.lineWidth = 2;
                        ctx.strokeRect(
                            detection.detection.box.x,
                            detection.detection.box.y,
                            detection.detection.box.width,
                            detection.detection.box.height
                        );

                        // Draw landmarks
                        if (detection.landmarks) {
                            ctx.fillStyle = '#00ff00';
                            detection.landmarks.positions.forEach(point => {
                                ctx.beginPath();
                                ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
                                ctx.fill();
                            });
                        }
                    });
                }
            } catch (error) {
                console.error('Detection error:', error);
                updateStatus('Face detection error. Retrying...', true);
            }

            requestAnimationFrame(detectFaces);
        }

        // Event Listeners
        startBtn.addEventListener('click', () => {
            if (modelLoaded) {
                isDetecting = true;
                stopBtn.disabled = false;
                startBtn.disabled = true;
                updateStatus('Face detection active');
                detectFaces();
            } else {
                updateStatus('Please wait for models to load', true);
            }
        });

        stopBtn.addEventListener('click', () => {
            isDetecting = false;
            stopBtn.disabled = true;
            startBtn.disabled = false;
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            updateStatus('Face detection stopped');
        });

        captureBtn.addEventListener('click', async () => {
            if (!modelLoaded) {
                updateStatus('Cannot capture - models not loaded', true);
                return;
            }

            const captureCanvas = document.createElement('canvas');
            captureCanvas.width = video.videoWidth;
            captureCanvas.height = video.videoHeight;
            const captureCtx = captureCanvas.getContext('2d');

            // Draw current video frame
            captureCtx.drawImage(video, 0, 0);

            try {
                // Detect faces in the captured frame
                const detections = await faceapi.detectAllFaces(
                    captureCanvas,
                    new faceapi.TinyFaceDetectorOptions()
                ).withFaceLandmarks();

                if (detections.length > 0) {
                    // Draw detections on captured frame
                    detections.forEach(detection => {
                        captureCtx.strokeStyle = '#00ff00';
                        captureCtx.lineWidth = 2;
                        captureCtx.strokeRect(
                            detection.detection.box.x,
                            detection.detection.box.y,
                            detection.detection.box.width,
                            detection.detection.box.height
                        );
                    });

                    // Save the image
                    const imageData = captureCanvas.toDataURL('image/png');
                    
                    // Create download link
                    const downloadLink = document.createElement('a');
                    downloadLink.href = imageData;
                    downloadLink.download = `face_capture_${new Date().toISOString()}.png`;
                    downloadLink.click();

                    updateStatus('Face captured and saved successfully!');
                } else {
                    updateStatus('No faces detected in capture', true);
                }
            } catch (error) {
                console.error('Capture error:', error);
                updateStatus('Error during capture', true);
            }
        });

        // Helper function to format date/time
        function formatDateTime(date) {
            return new Intl.DateTimeFormat('en-US', {
                year: 'numeric',
                month: '2-digit',
                day: '2-digit',
                hour: '2-digit',
                minute: '2-digit',
                second: '2-digit',
                hour12: false
            }).format(date);
        }

        // Initialize system with loading status
        document.addEventListener('DOMContentLoaded', async () => {
            updateStatus('Initializing face detection system...');
            
            // Add version and user info
            const versionInfo = document.createElement('div');
            versionInfo.className = 'status-message text-center mt-2';
            versionInfo.innerHTML = `
                <small>
                    System initialized by: ${ShanudhaTirosh}<br>
                    Last updated: ${formatDateTime(new Date())}
                </small>
            `;
            document.querySelector('.container').appendChild(versionInfo);

            // Load models and start video
            try {
                await loadModels();
                await startVideo();
            } catch (error) {
                console.error('Initialization error:', error);
                updateStatus('System initialization failed. Please refresh the page.', true);
            }
        });

        // Add error handling for video stream
        video.addEventListener('loadeddata', () => {
            updateStatus('Camera stream ready');
        });

        video.addEventListener('error', () => {
            updateStatus('Error with video stream. Please refresh.', true);
        });

        // Cleanup function
        window.addEventListener('beforeunload', () => {
            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>
