<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection System - Debug Version</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            min-height: 100vh;
            background: linear-gradient(45deg, #6a11cb, #2575fc);
            padding: 20px;
        }

        .glass-effect {
            background: rgba(255, 255, 255, 0.2);
            backdrop-filter: blur(8px);
            border-radius: 10px;
            border: 1px solid rgba(255, 255, 255, 0.18);
            padding: 20px;
            margin-bottom: 20px;
        }

        #video-container {
            position: relative;
            margin: auto;
            width: fit-content;
        }

        #face-canvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        .debug-info {
            background: rgba(0, 0, 0, 0.7);
            color: #fff;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
            font-family: monospace;
        }

        .loading-progress {
            height: 30px;
            background-color: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            overflow: hidden;
            margin: 10px 0;
        }

        .progress-bar {
            height: 100%;
            background-color: #00ff00;
            width: 0%;
            transition: width 0.3s ease;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Debug Information -->
        <div class="glass-effect">
            <h4 class="text-white">System Status</h4>
            <div id="debugInfo" class="debug-info">
                Initializing system...
            </div>
            <div class="loading-progress">
                <div id="progressBar" class="progress-bar"></div>
            </div>
        </div>

        <!-- Main Content -->
        <div class="row justify-content-center">
            <div class="col-lg-8">
                <div class="glass-effect">
                    <div id="video-container">
                        <video id="video" width="640" height="480" autoplay muted></video>
                        <canvas id="face-canvas" width="640" height="480"></canvas>
                    </div>
                    <div class="mt-3">
                        <button class="btn btn-primary me-2" id="startBtn" disabled>Start Detection</button>
                        <button class="btn btn-danger me-2" id="stopBtn" disabled>Stop Detection</button>
                        <button class="btn btn-success" id="captureBtn" disabled>Capture Face</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Debug logging function
        function updateDebug(message, isError = false) {
            const debugInfo = document.getElementById('debugInfo');
            const timestamp = new Date().toLocaleTimeString();
            debugInfo.innerHTML += `<div style="color: ${isError ? '#ff4444' : '#ffffff'}">[${timestamp}] ${message}</div>`;
            debugInfo.scrollTop = debugInfo.scrollHeight;
        }

        // Update progress bar
        function updateProgress(percent) {
            document.getElementById('progressBar').style.width = `${percent}%`;
        }

        // Load face-api.js script dynamically
        function loadScript(url) {
            return new Promise((resolve, reject) => {
                const script = document.createElement('script');
                script.src = url;
                script.onload = resolve;
                script.onerror = () => reject(new Error(`Failed to load script: ${url}`));
                document.head.appendChild(script);
            });
        }

        // Initialize system
        async function initializeSystem() {
            try {
                updateDebug('Loading required libraries...');
                updateProgress(10);

                // Load TensorFlow.js first
                await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js');
                updateDebug('TensorFlow.js loaded successfully');
                updateProgress(30);

                // Load Face-API.js
                await loadScript('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js');
                updateDebug('Face-API.js loaded successfully');
                updateProgress(50);

                // Wait for Face-API to be available
                await new Promise(resolve => setTimeout(resolve, 1000));

                // Load models
                updateDebug('Loading face detection models...');
                const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';
                
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
                    faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL)
                ]);

                updateDebug('Face detection models loaded successfully');
                updateProgress(80);

                // Initialize camera
                await initializeCamera();
                updateProgress(100);
                
                // Enable buttons
                document.getElementById('startBtn').disabled = false;
                document.getElementById('captureBtn').disabled = false;

                updateDebug('System initialization complete');

            } catch (error) {
                updateDebug(`Error during initialization: ${error.message}`, true);
                console.error('Initialization error:', error);
            }
        }

        // Initialize camera
        async function initializeCamera() {
            try {
                updateDebug('Accessing camera...');
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: 640,
                        height: 480,
                        facingMode: 'user'
                    }
                });

                const video = document.getElementById('video');
                video.srcObject = stream;
                updateDebug('Camera accessed successfully');

                return new Promise((resolve) => {
                    video.onloadeddata = () => {
                        updateDebug('Video stream ready');
                        resolve();
                    };
                });
            } catch (error) {
                updateDebug('Camera access failed: ' + error.message, true);
                throw error;
            }
        }

        // Face detection logic
        let isDetecting = false;
        const video = document.getElementById('video');
        const canvas = document.getElementById('face-canvas');
        const ctx = canvas.getContext('2d');

        async function detectFaces() {
            if (!isDetecting) return;

            try {
                const detections = await faceapi.detectAllFaces(
                    video,
                    new faceapi.TinyFaceDetectorOptions()
                ).withFaceLandmarks();

                ctx.clearRect(0, 0, canvas.width, canvas.height);

                detections.forEach(detection => {
                    // Draw face box
                    ctx.strokeStyle = '#00ff00';
                    ctx.lineWidth = 2;
                    ctx.strokeRect(
                        detection.detection.box.x,
                        detection.detection.box.y,
                        detection.detection.box.width,
                        detection.detection.box.height
                    );

                    // Draw landmarks
                    ctx.fillStyle = '#00ff00';
                    detection.landmarks.positions.forEach(point => {
                        ctx.beginPath();
                        ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
                        ctx.fill();
                    });
                });

                requestAnimationFrame(detectFaces);
            } catch (error) {
                updateDebug('Detection error: ' + error.message, true);
                isDetecting = false;
            }
        }

        // Button event listeners
        document.getElementById('startBtn').addEventListener('click', () => {
            isDetecting = true;
            document.getElementById('stopBtn').disabled = false;
            document.getElementById('startBtn').disabled = true;
            detectFaces();
            updateDebug('Face detection started');
        });

        document.getElementById('stopBtn').addEventListener('click', () => {
            isDetecting = false;
            document.getElementById('stopBtn').disabled = true;
            document.getElementById('startBtn').disabled = false;
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            updateDebug('Face detection stopped');
        });

        document.getElementById('captureBtn').addEventListener('click', () => {
            const captureCanvas = document.createElement('canvas');
            captureCanvas.width = video.videoWidth;
            captureCanvas.height = video.videoHeight;
            captureCanvas.getContext('2d').drawImage(video, 0, 0);
            
            const imageData = captureCanvas.toDataURL('image/png');
            const downloadLink = document.createElement('a');
            downloadLink.href = imageData;
            downloadLink.download = `face_capture_${new Date().toISOString()}.png`;
            downloadLink.click();
            
            updateDebug('Face captured and saved');
        });

        // Start initialization when page loads
        document.addEventListener('DOMContentLoaded', initializeSystem);
    </script>
</body>
</html>
